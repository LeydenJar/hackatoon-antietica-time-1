# 游 Como Rodar o Chat com IA

## Op칞칚o 1: Usando Docker (Recomendado)

### 1. Iniciar tudo com Docker Compose
```bash
docker-compose up -d
```

### 2. Acessar a interface
Abra seu navegador e v치 para: `http://localhost:3000`

## Op칞칚o 2: Rodar localmente

### 1. Instalar depend칡ncias
```bash
npm install
```

### 2. Iniciar o servidor
```bash
npm start
```

### 3. Acessar a interface
Abra seu navegador e v치 para: `http://localhost:3000`

## 游댢 O que est치 rodando

- **Ollama**: Container Docker rodando na porta 11434
- **Interface Web**: Servidor Express rodando na porta 3000
- **Modelo**: `custom-model` (seu modelo personalizado)

## 游닇 Notas importantes

- Certifique-se de que o Docker est치 rodando
- O Ollama precisa estar funcionando para a interface responder
- A interface se conecta automaticamente ao modelo `custom-model`
- Se der erro, verifique se o container Ollama est치 saud치vel

## 游냍 Troubleshooting

Se a interface n칚o responder:
1. Verifique se o Docker est치 rodando
2. Execute `docker-compose logs` para ver os logs
3. Verifique se o modelo `custom-model` est치 carregado no Ollama 